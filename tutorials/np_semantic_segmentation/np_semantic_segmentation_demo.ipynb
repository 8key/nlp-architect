{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NP Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all the relevant classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ayaccobi/ai-lab-nlp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'examples.np_semantic_segmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4333ed959dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_semantic_segmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNpSemanticSegData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_semantic_segmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_tratz2011\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_semantic_segmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnlp_architect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_semantic_segmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNpSemanticSegClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'examples.np_semantic_segmentation'"
     ]
    }
   ],
   "source": [
    "from examples.np_semantic_segmentation.data import NpSemanticSegData\n",
    "from examples.np_semantic_segmentation.preprocess_tratz2011 import *\n",
    "from examples.np_semantic_segmentation.data import *\n",
    "from nlp_architect.models.np_semantic_segmentation import NpSemanticSegClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is the download the dataset into a folder. You can download Tratz 2011 et al. dataset from the following link: [Tratz 2011 Dataset](https://vered1986.github.io/papers/Tratz2011_Dataset.tar.gz). Is also available in [here](https://www.isi.edu/publications/licensed-sw/fanseparser/index.html). (The terms and conditions of the data set license apply. Intel does not grant any rights to the data files or database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading and unzipping the dataset, the following method will labels some portion of the data, and will output two `.csv` files that will assist us to train and evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file is saved in /Users/ayaccobi/nlp_architect/data/np_semantic_segmentation/tratz2011_coarse_grained_random/train.csv\n",
      "CSV file is saved in /Users/ayaccobi/nlp_architect/data/np_semantic_segmentation/tratz2011_coarse_grained_random/val.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/Users/ayaccobi/nlp_architect/data/np_semantic_segmentation'\n",
    "preprocess_tratz_2011(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is saved and labeled we need to vectories the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_data_path is the output of preprocess_tratz_2011()\n",
    "labeled_train_data_path = '/Users/ayaccobi/nlp_architect/data/np_semantic_segmentation/tratz2011_coarse_grained_random/train.csv'\n",
    "labeled_val_data_path = '/Users/ayaccobi/nlp_architect/data/np_semantic_segmentation/tratz2011_coarse_grained_random/val.csv'\n",
    "word2vec_path = '/Users/ayaccobi/workspace/word_embeddings/GoogleNews-vectors-negative300.bin.gz'\n",
    "# output_path is location to save the vectors\n",
    "train_output_path = '/Users/ayaccobi/nlp_architect/data/np_semantic_segmentation/prepared_data_train.csv'\n",
    "val_output_path = '/Users/ayaccobi/nlp_architect/data/np_semantic_segmentation/prepared_data_val.csv'\n",
    "http_proxy = None\n",
    "https_proxy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading NLTK Collocation scoring (this might take a while...)\n",
      "Start loading Word2Vec model (this might take a while...)\n",
      "Finish loading feature extraction services\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:08<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared data CSV file is saved in /Users/ayaccobi/nlp_architect/data/np_semantic_segmentation/prepared_data_train.csv\n",
      "Start loading NLTK Collocation scoring (this might take a while...)\n",
      "Start loading Word2Vec model (this might take a while...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/ayaccobi/anaconda3/envs/fresh_env/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-789b147891e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_train_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_proxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttps_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_val_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_output_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_proxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttps_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ai-lab-nlp/examples/np_semantic_segmentation/data.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(data_file, output_file, word2vec_file, http_prox, https_prox)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mnltk_collocations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLTKCollocations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start loading Word2Vec model (this might take a while...)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finish loading feature extraction services\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mreader_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv_file_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-lab-nlp/examples/np_semantic_segmentation/feature_extraction.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, word2vec_model_path)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_word2vec_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-lab-nlp/examples/np_semantic_segmentation/feature_extraction.py\u001b[0m in \u001b[0;36mload_word2vec_model_from_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[1;32m    192\u001b[0m         word_embeddings_model = KeyedVectors.load_word2vec_format(\n\u001b[0;32m--> 193\u001b[0;31m             self.word2vec_model_path, binary=True)\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword_embeddings_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-lab-nlp/.nlp_architect_env/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1118\u001b[0m             \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai-lab-nlp/.nlp_architect_env/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'\\n'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# ignore newlines in front of words (some binary files have)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "prepare_data(labeled_train_data_path, train_output_path, word2vec_path, http_proxy, https_proxy)\n",
    "prepare_data(labeled_val_data_path, val_output_path, word2vec_path, http_proxy, https_proxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to load the data into NpSemanticSegmentation object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = NpSemanticSegData(train_output_path, train_to_test_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 0s - loss: 1.3596 - binary_accuracy: 0.5465 - precision_score: 0.1740 - recall_score: 0.3135 - f1: 0.2238\n",
      "Epoch 2/200\n",
      " - 0s - loss: 1.2109 - binary_accuracy: 0.6899 - precision_score: 0.2617 - recall_score: 0.2505 - f1: 0.2553\n",
      "Epoch 3/200\n",
      " - 0s - loss: 1.0886 - binary_accuracy: 0.7713 - precision_score: 0.3975 - recall_score: 0.2098 - f1: 0.2712\n",
      "Epoch 4/200\n",
      " - 0s - loss: 1.0250 - binary_accuracy: 0.7791 - precision_score: 0.1654 - recall_score: 0.0413 - f1: 0.0661\n",
      "Epoch 5/200\n",
      " - 0s - loss: 1.0474 - binary_accuracy: 0.7791 - precision_score: 0.3385 - recall_score: 0.0840 - f1: 0.1313\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.9737 - binary_accuracy: 0.7829 - precision_score: 0.3969 - recall_score: 0.0751 - f1: 0.1260\n",
      "Epoch 7/200\n",
      " - 0s - loss: 1.0561 - binary_accuracy: 0.7907 - precision_score: 0.4961 - recall_score: 0.0559 - f1: 0.0992\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.9731 - binary_accuracy: 0.7791 - precision_score: 0.2894 - recall_score: 0.0370 - f1: 0.0652\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.9084 - binary_accuracy: 0.7984 - precision_score: 0.3721 - recall_score: 0.0480 - f1: 0.0850\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.9810 - binary_accuracy: 0.7791 - precision_score: 0.1654 - recall_score: 0.0198 - f1: 0.0354\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.9554 - binary_accuracy: 0.7984 - precision_score: 0.7938 - recall_score: 0.0730 - f1: 0.1284\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.8866 - binary_accuracy: 0.7907 - precision_score: 0.2481 - recall_score: 0.0226 - f1: 0.0413\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.8608 - binary_accuracy: 0.7984 - precision_score: 0.3721 - recall_score: 0.0532 - f1: 0.0930\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.9911 - binary_accuracy: 0.7791 - precision_score: 0.0000e+00 - recall_score: 0.0000e+00 - f1: 0.0000e+00\n",
      "Epoch 15/200\n",
      " - 0s - loss: 1.0002 - binary_accuracy: 0.7868 - precision_score: 0.2481 - recall_score: 0.0165 - f1: 0.0310\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.9298 - binary_accuracy: 0.7868 - precision_score: 0.0000e+00 - recall_score: 0.0000e+00 - f1: 0.0000e+00\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.7084 - binary_accuracy: 0.8023 - precision_score: 0.3969 - recall_score: 0.0684 - f1: 0.1167\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.8909 - binary_accuracy: 0.7946 - precision_score: 0.5788 - recall_score: 0.0537 - f1: 0.0983\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.8182 - binary_accuracy: 0.8062 - precision_score: 0.9922 - recall_score: 0.0712 - f1: 0.1312\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.7742 - binary_accuracy: 0.7984 - precision_score: 0.7442 - recall_score: 0.0568 - f1: 0.1055\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.8198 - binary_accuracy: 0.8101 - precision_score: 0.9922 - recall_score: 0.0947 - f1: 0.1729\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.9652 - binary_accuracy: 0.7907 - precision_score: 0.2481 - recall_score: 0.0331 - f1: 0.0584\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.9271 - binary_accuracy: 0.7984 - precision_score: 0.6202 - recall_score: 0.0750 - f1: 0.1323\n",
      "Epoch 24/200\n",
      " - 0s - loss: 1.0138 - binary_accuracy: 0.7907 - precision_score: 0.6946 - recall_score: 0.0545 - f1: 0.0969\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.8461 - binary_accuracy: 0.8062 - precision_score: 0.8682 - recall_score: 0.0927 - f1: 0.1654\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.7761 - binary_accuracy: 0.8023 - precision_score: 0.9922 - recall_score: 0.0546 - f1: 0.1034\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.9376 - binary_accuracy: 0.8023 - precision_score: 0.4134 - recall_score: 0.0919 - f1: 0.1503\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.8711 - binary_accuracy: 0.7984 - precision_score: 0.7442 - recall_score: 0.0623 - f1: 0.1146\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.9489 - binary_accuracy: 0.7946 - precision_score: 0.7442 - recall_score: 0.0551 - f1: 0.0995\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.8292 - binary_accuracy: 0.8101 - precision_score: 0.7442 - recall_score: 0.1300 - f1: 0.2188\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.8250 - binary_accuracy: 0.8178 - precision_score: 0.9922 - recall_score: 0.1329 - f1: 0.2343\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.8268 - binary_accuracy: 0.8217 - precision_score: 0.8269 - recall_score: 0.1703 - f1: 0.2766\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.7844 - binary_accuracy: 0.8411 - precision_score: 0.9922 - recall_score: 0.2344 - f1: 0.3638\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.7505 - binary_accuracy: 0.8372 - precision_score: 0.9426 - recall_score: 0.2333 - f1: 0.3658\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.8018 - binary_accuracy: 0.8605 - precision_score: 0.9302 - recall_score: 0.3491 - f1: 0.5038\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.7776 - binary_accuracy: 0.8605 - precision_score: 0.9371 - recall_score: 0.3486 - f1: 0.5079\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.8547 - binary_accuracy: 0.8682 - precision_score: 0.9090 - recall_score: 0.4134 - f1: 0.5638\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.8151 - binary_accuracy: 0.8488 - precision_score: 1.0000 - recall_score: 0.2722 - f1: 0.4247\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.7278 - binary_accuracy: 0.8566 - precision_score: 0.8921 - recall_score: 0.3491 - f1: 0.4961\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.7573 - binary_accuracy: 0.8566 - precision_score: 0.9302 - recall_score: 0.3339 - f1: 0.4879\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.7786 - binary_accuracy: 0.8643 - precision_score: 0.9922 - recall_score: 0.3510 - f1: 0.5184\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.7575 - binary_accuracy: 0.8798 - precision_score: 0.9194 - recall_score: 0.4616 - f1: 0.6134\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.7357 - binary_accuracy: 0.8721 - precision_score: 0.9922 - recall_score: 0.3859 - f1: 0.5534\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.7797 - binary_accuracy: 0.8837 - precision_score: 0.9509 - recall_score: 0.4688 - f1: 0.6276\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.7013 - binary_accuracy: 0.8798 - precision_score: 0.9471 - recall_score: 0.4398 - f1: 0.6005\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.7541 - binary_accuracy: 0.8992 - precision_score: 0.9647 - recall_score: 0.5292 - f1: 0.6822\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.7372 - binary_accuracy: 0.8876 - precision_score: 0.9261 - recall_score: 0.5002 - f1: 0.6494\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6944 - binary_accuracy: 0.9031 - precision_score: 0.9922 - recall_score: 0.5450 - f1: 0.7034\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.7218 - binary_accuracy: 0.9070 - precision_score: 0.9922 - recall_score: 0.5520 - f1: 0.7092\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.7475 - binary_accuracy: 0.8876 - precision_score: 0.9214 - recall_score: 0.4961 - f1: 0.6448\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.7227 - binary_accuracy: 0.8915 - precision_score: 0.8820 - recall_score: 0.4920 - f1: 0.6190\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.7368 - binary_accuracy: 0.8798 - precision_score: 0.9509 - recall_score: 0.4410 - f1: 0.6023\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.7497 - binary_accuracy: 0.8876 - precision_score: 0.9509 - recall_score: 0.4755 - f1: 0.6339\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.7300 - binary_accuracy: 0.9070 - precision_score: 0.9370 - recall_score: 0.5808 - f1: 0.7156\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.7196 - binary_accuracy: 0.8915 - precision_score: 0.9922 - recall_score: 0.4806 - f1: 0.6474\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.7064 - binary_accuracy: 0.9225 - precision_score: 1.0000 - recall_score: 0.6293 - f1: 0.7714\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.7589 - binary_accuracy: 0.9031 - precision_score: 0.9478 - recall_score: 0.5710 - f1: 0.7051\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6976 - binary_accuracy: 0.9264 - precision_score: 0.9922 - recall_score: 0.6371 - f1: 0.7729\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6763 - binary_accuracy: 0.9186 - precision_score: 0.9922 - recall_score: 0.6164 - f1: 0.7595\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6565 - binary_accuracy: 0.9341 - precision_score: 0.9922 - recall_score: 0.6765 - f1: 0.8044\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.7504 - binary_accuracy: 0.9109 - precision_score: 0.8777 - recall_score: 0.6453 - f1: 0.7437\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6857 - binary_accuracy: 0.9264 - precision_score: 0.9774 - recall_score: 0.6676 - f1: 0.7866\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6817 - binary_accuracy: 0.9302 - precision_score: 0.9922 - recall_score: 0.6615 - f1: 0.7938\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.5787 - binary_accuracy: 0.9186 - precision_score: 0.9661 - recall_score: 0.6361 - f1: 0.7663\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.5808 - binary_accuracy: 0.9457 - precision_score: 0.9686 - recall_score: 0.7551 - f1: 0.8483\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.5517 - binary_accuracy: 0.9380 - precision_score: 0.9246 - recall_score: 0.7589 - f1: 0.8325\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6683 - binary_accuracy: 0.9419 - precision_score: 0.9686 - recall_score: 0.7360 - f1: 0.8357\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.7064 - binary_accuracy: 0.9302 - precision_score: 0.9416 - recall_score: 0.6951 - f1: 0.7996\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6560 - binary_accuracy: 0.9302 - precision_score: 0.9707 - recall_score: 0.6799 - f1: 0.7910\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6733 - binary_accuracy: 0.9264 - precision_score: 0.9096 - recall_score: 0.7169 - f1: 0.8006\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6074 - binary_accuracy: 0.9380 - precision_score: 0.9612 - recall_score: 0.7205 - f1: 0.8226\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.7777 - binary_accuracy: 0.9457 - precision_score: 0.9468 - recall_score: 0.7701 - f1: 0.8487\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6284 - binary_accuracy: 0.9380 - precision_score: 0.9516 - recall_score: 0.7540 - f1: 0.8389\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.6466 - binary_accuracy: 0.9380 - precision_score: 0.9647 - recall_score: 0.7166 - f1: 0.8203\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.5854 - binary_accuracy: 0.9496 - precision_score: 0.9774 - recall_score: 0.7753 - f1: 0.8644\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6424 - binary_accuracy: 0.9496 - precision_score: 0.9631 - recall_score: 0.7612 - f1: 0.8495\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6311 - binary_accuracy: 0.9574 - precision_score: 0.9922 - recall_score: 0.7905 - f1: 0.8799\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6238 - binary_accuracy: 0.9535 - precision_score: 0.9809 - recall_score: 0.7912 - f1: 0.8755\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.5650 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8195 - f1: 0.8999\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6333 - binary_accuracy: 0.9535 - precision_score: 0.9484 - recall_score: 0.8375 - f1: 0.8895\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6462 - binary_accuracy: 0.9535 - precision_score: 1.0000 - recall_score: 0.7698 - f1: 0.8685\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.5808 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8269 - f1: 0.9019\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.5918 - binary_accuracy: 0.9574 - precision_score: 0.9922 - recall_score: 0.7839 - f1: 0.8756\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6793 - binary_accuracy: 0.9380 - precision_score: 0.9091 - recall_score: 0.7733 - f1: 0.8357\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6193 - binary_accuracy: 0.9574 - precision_score: 0.9674 - recall_score: 0.8047 - f1: 0.8783\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6304 - binary_accuracy: 0.9496 - precision_score: 0.9450 - recall_score: 0.7876 - f1: 0.8592\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6157 - binary_accuracy: 0.9574 - precision_score: 0.9686 - recall_score: 0.8103 - f1: 0.8820\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.5454 - binary_accuracy: 0.9496 - precision_score: 0.9764 - recall_score: 0.7753 - f1: 0.8641\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.5917 - binary_accuracy: 0.9380 - precision_score: 0.9127 - recall_score: 0.7865 - f1: 0.8399\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.5465 - binary_accuracy: 0.9535 - precision_score: 0.9323 - recall_score: 0.8363 - f1: 0.8792\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.5236 - binary_accuracy: 0.9612 - precision_score: 0.9686 - recall_score: 0.8386 - f1: 0.8967\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6257 - binary_accuracy: 0.9496 - precision_score: 1.0000 - recall_score: 0.7649 - f1: 0.8652\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6686 - binary_accuracy: 0.9457 - precision_score: 0.9371 - recall_score: 0.7612 - f1: 0.8398\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.5952 - binary_accuracy: 0.9496 - precision_score: 0.9509 - recall_score: 0.7959 - f1: 0.8622\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.5838 - binary_accuracy: 0.9535 - precision_score: 0.9922 - recall_score: 0.7825 - f1: 0.8733\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.5730 - binary_accuracy: 0.9535 - precision_score: 0.9471 - recall_score: 0.8103 - f1: 0.8724\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.5594 - binary_accuracy: 0.9457 - precision_score: 0.9468 - recall_score: 0.7701 - f1: 0.8487\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.5702 - binary_accuracy: 0.9535 - precision_score: 0.9447 - recall_score: 0.7879 - f1: 0.8558\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.5984 - binary_accuracy: 0.9574 - precision_score: 0.9732 - recall_score: 0.8047 - f1: 0.8795\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6109 - binary_accuracy: 0.9535 - precision_score: 0.9724 - recall_score: 0.7878 - f1: 0.8683\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.5847 - binary_accuracy: 0.9496 - precision_score: 0.9716 - recall_score: 0.7717 - f1: 0.8573\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6714 - binary_accuracy: 0.9457 - precision_score: 0.9647 - recall_score: 0.7555 - f1: 0.8470\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.5561 - binary_accuracy: 0.9535 - precision_score: 1.0000 - recall_score: 0.7663 - f1: 0.8658\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.5848 - binary_accuracy: 0.9574 - precision_score: 0.9612 - recall_score: 0.7953 - f1: 0.8702\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.5443 - binary_accuracy: 0.9612 - precision_score: 0.9716 - recall_score: 0.8301 - f1: 0.8951\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.5377 - binary_accuracy: 0.9419 - precision_score: 0.9922 - recall_score: 0.7156 - f1: 0.8312\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.5780 - binary_accuracy: 0.9535 - precision_score: 1.0000 - recall_score: 0.7896 - f1: 0.8807\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.5413 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.7879 - f1: 0.8740\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.5017 - binary_accuracy: 0.9574 - precision_score: 1.0000 - recall_score: 0.7950 - f1: 0.8848\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6010 - binary_accuracy: 0.9574 - precision_score: 0.9922 - recall_score: 0.7901 - f1: 0.8787\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.5671 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8511 - f1: 0.9155\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6321 - binary_accuracy: 0.9535 - precision_score: 0.9802 - recall_score: 0.8132 - f1: 0.8884\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6474 - binary_accuracy: 0.9496 - precision_score: 0.9367 - recall_score: 0.8120 - f1: 0.8689\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.5262 - binary_accuracy: 0.9651 - precision_score: 0.9774 - recall_score: 0.8524 - f1: 0.9101\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.5996 - binary_accuracy: 0.9574 - precision_score: 0.9922 - recall_score: 0.8105 - f1: 0.8911\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6213 - binary_accuracy: 0.9496 - precision_score: 0.9405 - recall_score: 0.8118 - f1: 0.8666\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.5431 - binary_accuracy: 0.9574 - precision_score: 0.9922 - recall_score: 0.7959 - f1: 0.8812\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6120 - binary_accuracy: 0.9574 - precision_score: 0.9707 - recall_score: 0.8186 - f1: 0.8864\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.5655 - binary_accuracy: 0.9535 - precision_score: 0.9716 - recall_score: 0.7933 - f1: 0.8699\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.5999 - binary_accuracy: 0.9496 - precision_score: 0.9716 - recall_score: 0.7701 - f1: 0.8578\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.4722 - binary_accuracy: 0.9690 - precision_score: 0.9922 - recall_score: 0.8452 - f1: 0.9112\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.5344 - binary_accuracy: 0.9612 - precision_score: 0.9802 - recall_score: 0.8304 - f1: 0.8971\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.5166 - binary_accuracy: 0.9535 - precision_score: 0.9752 - recall_score: 0.7940 - f1: 0.8751\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.5626 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8248 - f1: 0.8999\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.4955 - binary_accuracy: 0.9574 - precision_score: 0.9922 - recall_score: 0.7919 - f1: 0.8800\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.5966 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8075 - f1: 0.8924\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.5806 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8175 - f1: 0.8956\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.5929 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.7988 - f1: 0.8836\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.5647 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8075 - f1: 0.8903\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.5470 - binary_accuracy: 0.9612 - precision_score: 0.9752 - recall_score: 0.8310 - f1: 0.8972\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.5796 - binary_accuracy: 0.9574 - precision_score: 0.9922 - recall_score: 0.7892 - f1: 0.8789\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.5551 - binary_accuracy: 0.9574 - precision_score: 1.0000 - recall_score: 0.8000 - f1: 0.8874\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.5900 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8147 - f1: 0.8977\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.5009 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8082 - f1: 0.8908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      " - 0s - loss: 0.5916 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8020 - f1: 0.8866\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.6098 - binary_accuracy: 0.9574 - precision_score: 0.9716 - recall_score: 0.8085 - f1: 0.8816\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.5857 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8314 - f1: 0.8998\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.5932 - binary_accuracy: 0.9612 - precision_score: 0.9816 - recall_score: 0.8246 - f1: 0.8937\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.5715 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8122 - f1: 0.8962\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.6000 - binary_accuracy: 0.9535 - precision_score: 0.9922 - recall_score: 0.7714 - f1: 0.8680\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.6036 - binary_accuracy: 0.9535 - precision_score: 0.9751 - recall_score: 0.7886 - f1: 0.8719\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.5672 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8103 - f1: 0.8920\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.5295 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8301 - f1: 0.9015\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.5632 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8143 - f1: 0.8973\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.5798 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8311 - f1: 0.9075\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.6314 - binary_accuracy: 0.9574 - precision_score: 0.9509 - recall_score: 0.8273 - f1: 0.8841\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.5376 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8386 - f1: 0.9056\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.5879 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8273 - f1: 0.9023\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.5283 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8148 - f1: 0.8926\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.5809 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8310 - f1: 0.9076\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.5692 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8312 - f1: 0.9045\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.5841 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8240 - f1: 0.9003\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.5798 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8342 - f1: 0.9088\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.5909 - binary_accuracy: 0.9612 - precision_score: 0.9686 - recall_score: 0.8269 - f1: 0.8920\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.6018 - binary_accuracy: 0.9419 - precision_score: 0.9278 - recall_score: 0.7701 - f1: 0.8404\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.5857 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8461 - f1: 0.9126\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.5855 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8269 - f1: 0.9020\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.6451 - binary_accuracy: 0.9574 - precision_score: 0.9555 - recall_score: 0.8314 - f1: 0.8815\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.5761 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8246 - f1: 0.9004\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.5822 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8138 - f1: 0.8972\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.5653 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8219 - f1: 0.8975\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.5758 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8287 - f1: 0.9023\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.5242 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8310 - f1: 0.9040\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.5570 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8219 - f1: 0.8975\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.5867 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8120 - f1: 0.8956\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.5346 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8120 - f1: 0.8956\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.5261 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8287 - f1: 0.9023\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.5520 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8287 - f1: 0.9023\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.5392 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8299 - f1: 0.9067\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.5391 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8269 - f1: 0.9020\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.4997 - binary_accuracy: 0.9690 - precision_score: 0.9922 - recall_score: 0.8423 - f1: 0.9092\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.5713 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8287 - f1: 0.9023\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.5567 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8273 - f1: 0.9023\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.5560 - binary_accuracy: 0.9612 - precision_score: 0.9647 - recall_score: 0.8148 - f1: 0.8823\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.5427 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8316 - f1: 0.9046\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.5129 - binary_accuracy: 0.9690 - precision_score: 1.0000 - recall_score: 0.8524 - f1: 0.9201\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.6096 - binary_accuracy: 0.9574 - precision_score: 0.9716 - recall_score: 0.8243 - f1: 0.8919\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.5736 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8211 - f1: 0.8976\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.6295 - binary_accuracy: 0.9574 - precision_score: 0.9504 - recall_score: 0.8260 - f1: 0.8838\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.5605 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8310 - f1: 0.9076\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.4899 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8287 - f1: 0.9023\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.5756 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8363 - f1: 0.9085\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.5723 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8110 - f1: 0.8910\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.5143 - binary_accuracy: 0.9690 - precision_score: 0.9922 - recall_score: 0.8330 - f1: 0.9042\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.5798 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8311 - f1: 0.9075\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.5663 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8044 - f1: 0.8909\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.5724 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8315 - f1: 0.9045\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.6172 - binary_accuracy: 0.9612 - precision_score: 0.9764 - recall_score: 0.8318 - f1: 0.8981\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.5652 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8175 - f1: 0.8956\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.5082 - binary_accuracy: 0.9690 - precision_score: 0.9922 - recall_score: 0.8618 - f1: 0.9224\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.5172 - binary_accuracy: 0.9612 - precision_score: 0.9774 - recall_score: 0.8346 - f1: 0.8990\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.5660 - binary_accuracy: 0.9535 - precision_score: 0.9686 - recall_score: 0.8064 - f1: 0.8792\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.5591 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8085 - f1: 0.8905\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.5594 - binary_accuracy: 0.9574 - precision_score: 0.9774 - recall_score: 0.8134 - f1: 0.8878\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.5778 - binary_accuracy: 0.9612 - precision_score: 0.9739 - recall_score: 0.8246 - f1: 0.8922\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.5766 - binary_accuracy: 0.9612 - precision_score: 0.9922 - recall_score: 0.8075 - f1: 0.8903\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.5799 - binary_accuracy: 0.9612 - precision_score: 1.0000 - recall_score: 0.8111 - f1: 0.8955\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.5780 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8301 - f1: 0.9033\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.5292 - binary_accuracy: 0.9651 - precision_score: 1.0000 - recall_score: 0.8304 - f1: 0.9061\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.5578 - binary_accuracy: 0.9651 - precision_score: 0.9922 - recall_score: 0.8287 - f1: 0.9023\n"
     ]
    }
   ],
   "source": [
    "    model_file_path = 'np_semantic_segmentation.h5'\n",
    "    model = NpSemanticSegClassifier(num_epochs=200, callback_args=None)\n",
    "    input_dim = data_set.train_set_x.shape[1]\n",
    "    model.build(input_dim)\n",
    "    model.fit(data_set.train_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have a MLP classifier for collocations. let evaluate it on the val_data_set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.3%\n",
      "Test binary_accuracy rate = 83.3%\n",
      "Test precision rate = 0.0%\n",
      "Test recall rate = 0.0%\n",
      "Test f1 rate = 0.0%\n"
     ]
    }
   ],
   "source": [
    "val_dataset = data_set = NpSemanticSegData(val_output_path, train_to_test_ratio=1)\n",
    "\n",
    "loss, binary_accuracy, precision, recall, f1 = model.eval(val_dataset.train_set)\n",
    "print('loss = %.1f%%' % (loss))\n",
    "print('Test binary_accuracy rate = %.1f%%' % (binary_accuracy * 100))\n",
    "print('Test precision rate = %.1f%%' % (precision * 100))\n",
    "print('Test recall rate = %.1f%%' % (recall * 100))\n",
    "print('Test f1 rate = %.1f%%' % (f1 * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
