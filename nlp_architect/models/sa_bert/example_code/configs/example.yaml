adam_epsilon: 1.0e-08
cache_dir: /home/daniel_nlp/nlp-architect/nlp_architect/cache
config_name: ''
data_dir: /home/daniel_nlp/nlp-architect/nlp_architect/models/sa_bert/data
do_predict: true
do_train: true
eval_batch_size: 32
fast_dev_run: false
gpus: 4
accumulate_grad_batches: 1
labels: /home/daniel_nlp/nlp-architect/nlp_architect/models/sa_bert/data/labels.txt
learning_rate: 5.0e-05
gradient_clip_val: 1.0
max_seq_length: 128
model_name_or_path: bert-base-multilingual-cased
n_tpu_cores: 0
max_epochs: 1
num_workers: 44
output_dir: /home/daniel_nlp/nlp-architect/nlp_architect/cache/models
overwrite_cache: true
resume_from_checkpoint: null
seed: 1
tokenizer_name: null
train_batch_size: 32
val_check_interval: 1.0
warmup_steps: 0
weight_decay: 0.0
logger: true