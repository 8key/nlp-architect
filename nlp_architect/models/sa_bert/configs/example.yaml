train_batch_size: 16
eval_batch_size: 16
max_seq_length: 64
seed: 12

max_epochs: 4
num_workers: 88
gpus: 1

model_type: sa-bert
model_name_or_path: bert-base-uncased

overwrite_cache: true
cache_dir: /home/daniel_nlp/nlp-architect/nlp_architect/cache
data_dir: /home/daniel_nlp/nlp-architect/nlp_architect/models/sa_bert/data/laptops_to_restaurants_1
labels: /home/daniel_nlp/nlp-architect/nlp_architect/models/sa_bert/data/labels.txt
output_dir: /home/daniel_nlp/nlp-architect/nlp_architect/cache/models

do_train: true
do_predict: false

adam_epsilon: 1.0e-08
fast_dev_run: false
accumulate_grad_batches: 1
learning_rate: 5.0e-05
gradient_clip_val: 1.0
n_tpu_cores: 0
resume_from_checkpoint: null
tokenizer_name: null
val_check_interval: 1.0
warmup_steps: 0
weight_decay: 0.0
logger: true

li_layer: 5
parse_probs: true
replace_final: false
random_init: false
all_layers: true
duplicated_rels: false
relation: ""
transpose: false
layers_range: [0,1,2,3,4,5,6,7,8,9,10,11,12]